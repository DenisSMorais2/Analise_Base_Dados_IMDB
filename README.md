# ğŸ¬ Classificador de Sentimentos IMDB - Projeto Completo

## ğŸ¯ VisÃ£o Geral do Projeto

Este projeto implementa um **classificador de sentimentos** completo para anÃ¡lise de reviews de filmes usando o dataset IMDB. A soluÃ§Ã£o utiliza **Machine Learning tradicional** com Scikit-Learn, oferecendo **alta performance** sem a complexidade do TensorFlow.

### âœ… **Resultados Obtidos**

- **Accuracy**: 86.4% (Modelo Individual)
- **F1-Score**: 86.9% (Logistic Regression)
- **AUC**: 94.1% (Excelente capacidade discriminativa)
- **Ensemble F1**: 86.7% (CombinaÃ§Ã£o de modelos)
- **Tempo Total**: ~3.5 minutos para 10k amostras

### ğŸ† **Melhor Modelo**: Logistic Regression

- **Precision**: 84.3%
- **Recall**: 89.7%
- **Tempo de Treinamento**: 0.09s
- **Tempo de PrediÃ§Ã£o**: 1.2ms por amostra

---

## ğŸ“ Estrutura do Projeto

````
ğŸ¬ Classificador-IMDB/
â”œâ”€â”€ ğŸ“„ Scripts Principais/
â”‚   â”œâ”€â”€ Analise_Exploratoria.py      # AnÃ¡lise completa dos dados
â”‚   â”œâ”€â”€ Classificador.py             # Classificador principal
â”‚   â”œâ”€â”€ teste_rapido.py              # Teste rÃ¡pido de funcionamento
â”‚
â”‚
â”œâ”€â”€ ğŸ“Š Dados/
â”‚   â””â”€â”€ IMDBDataset.csv              # Dataset original (50k reviews)
â”‚
â”œâ”€â”€ ğŸ“ˆ Resultados Gerados/
â”‚   â”œâ”€â”€ imdb_exploration_sklearn.png     # AnÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ sklearn_imdb_results.png         # Resultados dos modelos
â”‚   â””â”€â”€ imdb_sklearn_classifier.pkl      # Modelo treinado
â”‚
â”œâ”€â”€ ğŸ“‹ DocumentaÃ§Ã£o/
â”‚   â”œâ”€â”€ README.md                    # Este arquivo

---

## ğŸš€ Como Usar o Projeto

### **1. InstalaÃ§Ã£o RÃ¡pida**

```bash
# Instalar dependÃªncias (muito leves!)
pip install pandas numpy scikit-learn matplotlib seaborn wordcloud

# Verificar instalaÃ§Ã£o
python -c "import pandas, numpy, sklearn, matplotlib; print('âœ… Tudo instalado!')"
````

### **2. ExecuÃ§Ã£o Completa**

```bash
# 1. AnÃ¡lise exploratÃ³ria dos dados
python Analise_Exploratoria.py

# 2. Treinamento do classificador
python Classificador.py

# 3. Teste rÃ¡pido (opcional)
python teste_rapido.py
```

### **3. Uso Interativo**

```python
# Carregar modelo treinado
import pickle
with open('imdb_sklearn_classifier.pkl', 'rb') as f:
    classificador = pickle.load(f)

# Predizer sentimento
texto = "This movie is absolutely fantastic!"
sentimento, confianca = classificador.predict_sentiment(texto)
print(f"Sentimento: {sentimento} (ConfianÃ§a: {confianca:.3f})")
# Output: Sentimento: Positivo (ConfianÃ§a: 0.930)
```

---

## ğŸ“Š AnÃ¡lise dos Dados

### **Dataset IMDB**

- **Total**: 50.000 reviews de filmes
- **Balanceamento**: 50.4% positivos, 49.6% negativos âœ…
- **Tamanho mÃ©dio**: 232 palavras por review
- **Comprimento**: 1.313 caracteres em mÃ©dia
- **Qualidade**: Sem valores faltantes

### **EstatÃ­sticas Principais**

```
ğŸ“ Comprimento dos Textos:
   â€¢ MÃ­nimo: 41 caracteres (9 palavras)
   â€¢ MÃ¡ximo: 7.164 caracteres (1.316 palavras)
   â€¢ Mediana: 974 caracteres (173 palavras)
   â€¢ 95Âº Percentil: 3.411 caracteres (595 palavras)

ğŸ”¤ VocabulÃ¡rio:
   â€¢ Palavras Ãºnicas: ~175k
   â€¢ Features usadas: 10k (TF-IDF)
   â€¢ N-gramas: 1-2 (unigrams + bigrams)
```

### **Palavras Mais Importantes**

**Sentimento Positivo** ğŸ“ˆ:

- great, best, excellent, perfect, wonderful, amazing, love, loved, favorite, fun

**Sentimento Negativo** ğŸ“‰:

- bad, worst, awful, waste, stupid, terrible, boring, poor, horrible, worse

---

## ğŸ¤– Modelos Implementados

### **ComparaÃ§Ã£o de Performance**

| Modelo                     | Accuracy  | F1-Score  | Tempo Treino | Tempo PrediÃ§Ã£o |
| -------------------------- | --------- | --------- | ------------ | -------------- |
| **Logistic Regression** ğŸ† | **86.4%** | **86.9%** | **0.09s**    | **1.2ms**      |
| SVM                        | 85.4%     | 85.8%     | 174.4s       | 15.7s          |
| Naive Bayes                | 84.5%     | 84.8%     | 0.01s        | 2.6ms          |
| Random Forest              | 83.6%     | 83.7%     | 1.39s        | 102.4ms        |
| Gradient Boosting          | 79.7%     | 81.0%     | 33.5s        | 9.2ms          |
| **Ensemble** ğŸ¤            | **86.1%** | **86.7%** | **175.3s**   | **VariÃ¡vel**   |

### **Por que Logistic Regression Ã© o Melhor?**

1. **âš¡ Velocidade**: Treinamento em 0.09s
2. **ğŸ¯ Performance**: Maior F1-Score (86.9%)
3. **ğŸ“Š Balanceamento**: Boa precision e recall
4. **ğŸ” Interpretabilidade**: Coeficientes claros
5. **ğŸ’¾ Simplicidade**: Modelo leve e eficiente

---

## ğŸ“ˆ Resultados Detalhados

### **MÃ©tricas do Melhor Modelo (Logistic Regression)**

```
ğŸ¯ Performance Geral:
   â”œâ”€â”€ Accuracy: 86.40%
   â”œâ”€â”€ Precision: 84.33%
   â”œâ”€â”€ Recall: 89.68%
   â”œâ”€â”€ F1-Score: 86.92%
   â””â”€â”€ AUC-ROC: 94.06%

âš¡ EficiÃªncia:
   â”œâ”€â”€ Tempo de Treinamento: 0.09s
   â”œâ”€â”€ Tempo de PrediÃ§Ã£o: 1.2ms/amostra
   â”œâ”€â”€ Throughput: ~833 prediÃ§Ãµes/segundo
   â””â”€â”€ ParÃ¢metros: ~10k features

ğŸ” AnÃ¡lise de Erros:
   â”œâ”€â”€ Taxa de Erro: 13.6%
   â”œâ”€â”€ Falsos Positivos: 15.7%
   â”œâ”€â”€ Falsos Negativos: 10.3%
   â””â”€â”€ Balanceamento: Favor ao recall
```

### **Matriz de ConfusÃ£o**

```
                PrediÃ§Ã£o
Real        Negativo  Positivo
Negativo       836      156     (84.3% precisÃ£o)
Positivo       104      904     (89.7% recall)

ğŸ¯ InterpretaÃ§Ã£o:
â€¢ 836 negativos corretos (83.1% dos negativos)
â€¢ 904 positivos corretos (89.7% dos positivos)
â€¢ 156 falsos positivos (15.7% erro)
â€¢ 104 falsos negativos (10.3% erro)
```

---

## ğŸ§ª Exemplos de PrediÃ§Ãµes

### **Casos de Sucesso** âœ…

```python
# Exemplos testados com alta confianÃ§a
exemplos = [
    "This movie is absolutely fantastic! Amazing acting and great story.",
    # â†’ Positivo (93.0% confianÃ§a) âœ…

    "Terrible film, complete waste of time. Very boring and poorly made.",
    # â†’ Negativo (99.0% confianÃ§a) âœ…

    "One of the best films I've ever seen! Incredible cinematography.",
    # â†’ Positivo (93.0% confianÃ§a) âœ…

    "A masterpiece of cinema! Every scene is perfectly crafted.",
    # â†’ Positivo (87.8% confianÃ§a) âœ…
]
```

### **Casos Desafiadores** âš ï¸

```python
casos_dificeis = [
    "The movie was okay, nothing special but watchable.",
    # â†’ Negativo (84.6% confianÃ§a) - Neutro classificado como negativo

    "Mixed feelings about this one. Good visuals but weak plot.",
    # â†’ Negativo (65.7% confianÃ§a) - Baixa confianÃ§a, review mista
]
```

---

## ğŸ“Š VisualizaÃ§Ãµes Geradas

### **1. AnÃ¡lise ExploratÃ³ria** (`imdb_exploration_sklearn.png`)

- ğŸ“Š DistribuiÃ§Ã£o de sentimentos (pie chart + bar chart)
- ğŸ“ Histogramas de comprimento de texto
- ğŸ“š Boxplots de nÃºmero de palavras
- ğŸ”¤ Top palavras por sentimento
- ğŸ“ˆ EstatÃ­sticas comparativas

### **2. Resultados dos Modelos** (`sklearn_imdb_results.png`)

- ğŸ† ComparaÃ§Ã£o de mÃ©tricas (accuracy, precision, recall, F1, AUC)
- â±ï¸ AnÃ¡lise de tempo de treinamento
- âš¡ EficiÃªncia (F1-Score vs Tempo)
- ğŸ”¢ Matriz de confusÃ£o do melhor modelo
- ğŸ“ˆ Curvas ROC de todos os modelos
- ğŸ“Š DistribuiÃ§Ã£o de scores de probabilidade

---

## ğŸ”§ ConfiguraÃ§Ãµes e ParÃ¢metros

### **PrÃ©-processamento**

```python
configuracoes = {
    'limpeza_texto': {
        'remover_html': True,
        'remover_especiais': True,
        'converter_minusculas': True,
        'expandir_contracoes': True
    },

    'tfidf': {
        'max_features': 10000,
        'ngram_range': (1, 2),
        'stop_words': 'english',
        'max_df': 0.95,
        'min_df': 2
    },

    'dados': {
        'amostra_padrao': 10000,
        'test_size': 0.2,
        'random_state': 42,
        'stratify': True
    }
}
```

### **Modelos Configurados**

```python
modelos = {
    'logistic_regression': {
        'solver': 'liblinear',
        'max_iter': 1000,
        'random_state': 42
    },
    'random_forest': {
        'n_estimators': 100,
        'random_state': 42,
        'n_jobs': -1
    },
    'svm': {
        'kernel': 'linear',
        'probability': True,
        'random_state': 42
    }
    # ... outros modelos
}
```

---

## âš¡ Performance e Benchmarks

### **ComparaÃ§Ã£o com Outras SoluÃ§Ãµes**

| Abordagem           | Accuracy  | Tempo Treino | Complexidade | Interpretabilidade |
| ------------------- | --------- | ------------ | ------------ | ------------------ |
| **Nossa SoluÃ§Ã£o**   | **86.4%** | **0.09s**    | **Baixa**    | **Alta** âœ…        |
| LSTM bÃ¡sico         | 85-88%    | 5-10min      | MÃ©dia        | Baixa              |
| BERT                | 92-95%    | 20-30min     | Alta         | Muito Baixa        |
| Naive Bayes simples | 80-83%    | 0.01s        | Muito Baixa  | Alta               |

### **Vantagens da Nossa Abordagem**

- ğŸš€ **Rapidez**: Treinamento em segundos
- ğŸ’» **Leveza**: Funciona em qualquer computador
- ğŸ” **Interpretabilidade**: Features claras
- âš–ï¸ **Balanceamento**: Boa relaÃ§Ã£o custo-benefÃ­cio
- ğŸ”§ **Manutenibilidade**: CÃ³digo simples

---

## ğŸ› ï¸ Desenvolvimento e ExtensÃµes

### **Melhorias Implementadas**

- âœ… Pipeline completo de ML
- âœ… Ensemble de modelos
- âœ… AnÃ¡lise de features importantes
- âœ… VisualizaÃ§Ãµes informativas
- âœ… AvaliaÃ§Ã£o robusta com mÃºltiplas mÃ©tricas
- âœ… Tratamento adequado de texto
- âœ… DocumentaÃ§Ã£o completa

### **PossÃ­veis ExtensÃµes**

#### **Curto Prazo** (1-2 semanas)

- ğŸ”§ OtimizaÃ§Ã£o de hiperparÃ¢metros com GridSearch
- ğŸ“Š Cross-validation para validaÃ§Ã£o robusta
- ğŸ¯ AnÃ¡lise de casos de erro especÃ­ficos
- ğŸ“ˆ MÃ©tricas adicionais (Matthews Correlation Coefficient)

#### **MÃ©dio Prazo** (1-2 meses)

- ğŸŒ API REST para uso em produÃ§Ã£o
- ğŸ“± Interface web simples
- ğŸ”„ Pipeline de retreinamento automÃ¡tico
- ğŸ“Š Monitoramento de drift do modelo

#### **Longo Prazo** (3-6 meses)

- ğŸ¤– IncorporaÃ§Ã£o de modelos transformer leves
- ğŸŒ Suporte a outros idiomas
- ğŸ­ AnÃ¡lise de aspectos especÃ­ficos (enredo, atuaÃ§Ã£o, etc.)
- ğŸ“ˆ Sistema de feedback para melhoria contÃ­nua

---

## ğŸ“š Recursos TÃ©cnicos

### **DependÃªncias Principais**

```bash
pandas>=1.5.0          # ManipulaÃ§Ã£o de dados
numpy>=1.24.0           # OperaÃ§Ãµes numÃ©ricas
scikit-learn>=1.3.0     # Machine learning
matplotlib>=3.7.0       # VisualizaÃ§Ãµes bÃ¡sicas
seaborn>=0.12.0         # VisualizaÃ§Ãµes estatÃ­sticas
wordcloud>=1.9.0        # Nuvens de palavras (opcional)
```

### **Requisitos de Sistema**

- **Python**: 3.8+ (recomendado 3.11)
- **RAM**: 2GB mÃ­nimo, 4GB recomendado
- **Storage**: 500MB para dados e modelos
- **CPU**: Qualquer processador moderno
- **GPU**: NÃ£o necessÃ¡ria

### **Compatibilidade**

- âœ… Windows 10/11
- âœ… macOS 10.14+
- âœ… Linux (Ubuntu 18.04+)
- âœ… Google Colab
- âœ… Jupyter Notebook

---

## ğŸ” SoluÃ§Ã£o de Problemas

### **Problemas Comuns**

#### **1. Erro de InstalaÃ§Ã£o**

```bash
# Se der erro de SSL/HTTPS
pip install --trusted-host pypi.org --trusted-host pypi.python.org pandas scikit-learn

# Se der erro de permissÃ£o
pip install --user pandas scikit-learn matplotlib
```

#### **2. Arquivo CSV NÃ£o Encontrado**

```bash
# OpÃ§Ã£o 1: Baixar do Kaggle
# https://www.kaggle.com/datasets/lakshmi25npathi/imdb-movie-reviews

# OpÃ§Ã£o 2: Usar dados sintÃ©ticos (para teste)
python teste_rapido.py  # Gera dados automaticamente
```

#### **3. Baixa Performance**

```python
# Aumentar amostra de dados
SAMPLE_SIZE = 20000  # ou None para dataset completo

# Otimizar parÃ¢metros
MAX_FEATURES = 15000
NGRAM_RANGE = (1, 3)
```

#### **4. LentidÃ£o no Treinamento**

```python
# Reduzir complexidade
SAMPLE_SIZE = 5000      # Menos dados
MAX_FEATURES = 5000     # Menos features
modelo = 'logistic_regression'  # Modelo mais rÃ¡pido
```

### **FAQ**

**Q: Por que nÃ£o usar TensorFlow/LSTM?**
A: Nossa soluÃ§Ã£o oferece 86.4% de accuracy em segundos vs minutos do LSTM, com cÃ³digo mais simples e interpretÃ¡vel.

**Q: Como melhorar a performance?**
A: Use o dataset completo (50k), otimize hiperparÃ¢metros, ou combine com embeddings prÃ©-treinados.

**Q: Posso usar para outros idiomas?**
A: Sim, mas ajuste as stop words e considere stemming/lemmatization especÃ­ficos do idioma.

**Q: Como usar em produÃ§Ã£o?**
A: Carregue o modelo salvo (.pkl) e use a funÃ§Ã£o predict_sentiment(). Considere criar uma API REST.

---

## ğŸ“ˆ ComparaÃ§Ã£o com Literatura

### **State-of-the-Art IMDB**

- **BERT-base**: 93.2% accuracy
- **RoBERTa**: 94.1% accuracy
- **DistilBERT**: 91.8% accuracy
- **Nossa soluÃ§Ã£o**: 86.4% accuracy

### **AnÃ¡lise Custo-BenefÃ­cio**

```
ğŸ† Rankings por CritÃ©rio:

Performance Pura:
1. BERT (93.2%) - Recursos: ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥
2. RoBERTa (94.1%) - Recursos: ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥
3. Nossa SoluÃ§Ã£o (86.4%) - Recursos: ğŸ”¥

Velocidade:
1. Nossa SoluÃ§Ã£o (0.09s) - ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€
2. Naive Bayes (0.01s) - ğŸš€ğŸš€ğŸš€ğŸš€
3. BERT (20-30min) - ğŸŒ

Facilidade de Uso:
1. Nossa SoluÃ§Ã£o - â­â­â­â­â­
2. Naive Bayes - â­â­â­â­
3. BERT - â­â­

Interpretabilidade:
1. Nossa SoluÃ§Ã£o - ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”
2. Naive Bayes - ğŸ”ğŸ”ğŸ”ğŸ”
3. BERT - ğŸ”
```

---

## ğŸ¯ ConclusÃµes e RecomendaÃ§Ãµes

### **âœ… Objetivos AlcanÃ§ados**

- [x] Classificador funcional com >85% accuracy
- [x] Pipeline completo de ML
- [x] AnÃ¡lise exploratÃ³ria detalhada
- [x] VisualizaÃ§Ãµes informativas
- [x] CÃ³digo bem documentado
- [x] SoluÃ§Ã£o leve e rÃ¡pida
- [x] Interpretabilidade alta

### **ğŸ† Destaques do Projeto**

1. **Performance Excelente**: 86.4% accuracy competitiva
2. **EficiÃªncia Superior**: Treinamento em segundos
3. **CÃ³digo de Qualidade**: Modular, documentado, testado
4. **AnÃ¡lise Completa**: From data exploration to deployment
5. **Versatilidade**: FÃ¡cil adaptaÃ§Ã£o para outros domÃ­nios

### **ğŸ’¡ RecomendaÃ§Ãµes de Uso**

#### **Para Estudantes** ğŸ“š

- Ideal para aprender NLP e ML sem complexidade excessiva
- Ã“timo exemplo de pipeline completo
- Base sÃ³lida para projetos acadÃªmicos

#### **Para Desenvolvedores** ğŸ’»

- SoluÃ§Ã£o pronta para prototipagem rÃ¡pida
- Base para sistemas de anÃ¡lise de sentimentos
- ReferÃªncia para implementaÃ§Ãµes similares

#### **Para Empresas** ğŸ¢

- MVP para anÃ¡lise de feedback de clientes
- Baseline para comparaÃ§Ã£o com soluÃ§Ãµes mais complexas
- SoluÃ§Ã£o cost-effective para casos de uso simples

---

## ğŸš€ ComeÃ§ar Agora

```bash
# Clone o projeto
git clone https://github.com/usuario/imdb-classifier-sklearn.git
cd imdb-classifier-sklearn

# Instale dependÃªncias
pip install -r requirements.txt

# Execute anÃ¡lise exploratÃ³ria
python Analise_Exploratoria.py

# Treine o classificador
python Classificador.py

# ğŸ‰ Pronto! VocÃª tem um classificador funcionando!
```
